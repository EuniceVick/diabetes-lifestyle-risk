{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e9a075",
   "metadata": {},
   "source": [
    "# Diabetes Risk Prediction from Lifestyle Factors\n",
    "\n",
    "End‑to‑end: EDA, CV models, threshold tuning, calibration, SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, joblib, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score, confusion_matrix,\n",
    "                             roc_curve, precision_recall_curve, brier_score_loss)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import shap, numpy as _np\n",
    "if not hasattr(_np, \"bool\"): _np.bool = _np.bool_\n",
    "warnings.filterwarnings(\"ignore\"); np.random.seed(42)\n",
    "DATA_PATH = Path(\"data/cleaned_diabetes_lifestyle.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d2d3e",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef11887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_PATH).dropna(subset=[\"Diabetic\"]).copy()\n",
    "print(\"Shape:\", df.shape); df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc00055",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa130aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counts = df['Diabetic'].value_counts().sort_index()\n",
    "plt.figure(); plt.bar(['Non-diabetic(0)','Diabetic(1)'], counts.values); plt.title('Class Distribution'); plt.show()\n",
    "num_cols = [c for c in ['Age','BMI','Sleep','SoundSleep','Pregancies'] if c in df.columns]\n",
    "df[num_cols].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae44c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in [c for c in ['BMI','Sleep','SoundSleep'] if c in df.columns]:\n",
    "    plt.figure(); plt.boxplot([df[df['Diabetic']==0][col], df[df['Diabetic']==1][col]], labels=['0','1'])\n",
    "    plt.title(f'{col} by Diabetes'); plt.ylabel(col); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e2647",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=['Diabetic']); y = df['Diabetic'].astype(int)\n",
    "numeric_cols = [c for c in ['Age','BMI','Sleep','SoundSleep','Pregancies'] if c in X.columns]\n",
    "other_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "other_transformer = Pipeline([('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "preprocess = ColumnTransformer([('num', numeric_transformer, numeric_cols), ('other', other_transformer, other_cols)], remainder='drop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08382e21",
   "metadata": {},
   "source": [
    "## 4. CV Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12eeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"lbfgs\"),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, min_samples_leaf=2, class_weight=\"balanced\", random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\", random_state=42)\n",
    "}\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\"roc_auc\":\"roc_auc\",\"avg_prec\":\"average_precision\",\"f1\":\"f1\",\"recall\":\"recall\",\"precision\":\"precision\",\"accuracy\":\"accuracy\"}\n",
    "rows=[]\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", model)])\n",
    "    cv = cross_validate(pipe, X, y, cv=skf, scoring=scoring)\n",
    "    rows.append({\"Model\":name,\"ROC_AUC (CV mean)\":float(np.mean(cv[\"test_roc_auc\"])),\n",
    "                 \"PR_AUC (CV mean)\":float(np.mean(cv[\"test_avg_prec\"])),\n",
    "                 \"F1 (CV mean)\":float(np.mean(cv[\"test_f1\"])),\n",
    "                 \"Recall (CV mean)\":float(np.mean(cv[\"test_recall\"])),\n",
    "                 \"Precision (CV mean)\":float(np.mean(cv[\"test_precision\"])),\n",
    "                 \"Accuracy (CV mean)\":float(np.mean(cv[\"test_accuracy\"]))})\n",
    "cv_df = pd.DataFrame(rows).sort_values(\"ROC_AUC (CV mean)\", ascending=False).reset_index(drop=True)\n",
    "cv_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53eef62",
   "metadata": {},
   "source": [
    "## 5. Train Best, Tune Threshold, Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7beab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "best_name = cv_df.iloc[0][\"Model\"]; best_model = models[best_name]\n",
    "best_pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", best_model)]).fit(X_train, y_train)\n",
    "proba = best_pipe.predict_proba(X_test)[:,1]; pred = (proba>=0.5).astype(int)\n",
    "def metrics(y_true, y_prob, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return {\"Accuracy\":accuracy_score(y_true,y_pred),\"Precision\":precision_score(y_true,y_pred),\n",
    "            \"Recall\":recall_score(y_true,y_pred),\"F1\":f1_score(y_true,y_pred),\n",
    "            \"ROC_AUC\":roc_auc_score(y_true,y_prob),\"PR_AUC\":average_precision_score(y_true,y_prob),\n",
    "            \"TN\":int(tn),\"FP\":int(fp),\"FN\":int(fn),\"TP\":int(tp)}\n",
    "default_metrics = metrics(y_test, proba, pred); pd.DataFrame([default_metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf09e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ths = np.linspace(0.01,0.99,99); f1s=[f1_score(y_test,(proba>=t).astype(int)) for t in ths]\n",
    "best_t = float(ths[int(np.argmax(f1s))]); pred_t = (proba>=best_t).astype(int)\n",
    "tuned_metrics = metrics(y_test, proba, pred_t); tuned_metrics[\"Threshold\"]=best_t\n",
    "pd.DataFrame([tuned_metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dccc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "plt.figure(); plt.plot(fpr,tpr,label='ROC'); plt.plot([0,1],[0,1],'--'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title(f'ROC — {best_name}'); plt.legend(); plt.show()\n",
    "prec, rec, _ = precision_recall_curve(y_test, proba)\n",
    "plt.figure(); plt.plot(rec,prec,label='PR'); plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title(f'PR — {best_name}'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d153ab",
   "metadata": {},
   "source": [
    "## 6. Calibration (Platt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c89092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "platt = CalibratedClassifierCV(RandomForestClassifier(n_estimators=200, min_samples_leaf=2, class_weight='balanced', random_state=42),\n",
    "                               method='sigmoid', cv=3)\n",
    "cal_pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", platt)]).fit(X_train, y_train)\n",
    "proba_cal = cal_pipe.predict_proba(X_test)[:,1]; pred_cal = (proba_cal>=0.5).astype(int)\n",
    "cal_metrics = metrics(y_test, proba_cal, pred_cal); cal_metrics[\"Brier\"]=brier_score_loss(y_test, proba_cal)\n",
    "pd.DataFrame([cal_metrics])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebfc055",
   "metadata": {},
   "source": [
    "## 7. SHAP (global, local, interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if best_name in [\"RandomForest\",\"GradientBoosting\"]:\n",
    "    feats = best_pipe.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "    Xt = best_pipe.named_steps[\"preprocess\"].transform(X_test)\n",
    "    model = best_pipe.named_steps[\"model\"]\n",
    "    expl = shap.TreeExplainer(model)\n",
    "    vals = expl.shap_values(Xt)\n",
    "    shap.summary_plot(vals[1], Xt, feature_names=feats, plot_type=\"bar\")\n",
    "    shap.summary_plot(vals[1], Xt, feature_names=feats)\n",
    "    pos = int(np.where(y_test.values==1)[0][0]); neg = int(np.where(y_test.values==0)[0][0])\n",
    "    shap.plots._waterfall.waterfall_legacy(expl.expected_value[1], vals[1][pos,:], feature_names=feats, max_display=20)\n",
    "    shap.plots._waterfall.waterfall_legacy(expl.expected_value[1], vals[1][neg,:], feature_names=feats, max_display=20)\n",
    "    sample = min(150, Xt.shape[0]); inter = expl.shap_interaction_values(Xt[:sample])\n",
    "    inter_mean = np.abs(inter[1]).mean(axis=0)\n",
    "    import pandas as pd, matplotlib.pyplot as plt\n",
    "    inter_df = pd.DataFrame(inter_mean, index=feats, columns=feats)\n",
    "    top = inter_df.mean(axis=1).sort_values(ascending=False).head(15).index\n",
    "    plt.figure(figsize=(8,6)); plt.imshow(inter_df.loc[top, top], aspect='auto'); plt.colorbar(); plt.title('SHAP Interaction Heatmap (Top 15)')\n",
    "    plt.xticks(range(len(top)), top, rotation=90); plt.yticks(range(len(top)), top); plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"Best model not tree-based; SHAP skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eee9a2",
   "metadata": {},
   "source": [
    "## 8. Save Pipeline & Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1652bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib, json\n",
    "from pathlib import Path\n",
    "Path(\"models\").mkdir(exist_ok=True, parents=True)\n",
    "joblib.dump(best_pipe, Path(\"models\")/\"diabetes_lifestyle_pipeline.pkl\")\n",
    "meta = {\"best_model\":best_name,\"threshold_default\":0.5,\"threshold_max_f1\":best_t,\n",
    "        \"default_metrics\":default_metrics,\"tuned_metrics\":tuned_metrics}\n",
    "with open(Path(\"models\")/\"diabetes_lifestyle_pipeline_info.json\",\"w\") as f: json.dump(meta, f, indent=2)\n",
    "print(\"Saved to models/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
